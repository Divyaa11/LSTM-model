import random
import math
import re
import csv
import os
import pandas as pd
import sklearn
from sklearn import metrics
from sklearn.utils import shuffle
import numpy as np 
import matplotlib.pyplot as plt #just plot
import seaborn as sns
import keras
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from keras.models import load_model
from keras.models import Model
from keras.layers import LSTM, Dense, Activation, Input, Embedding, Dropout
from keras.optimizers import RMSprop
from keras.preprocessing.text import Tokenizer
from keras.preprocessing import sequence
from keras.utils import to_categorical, pad_sequences
from keras.callbacks import EarlyStopping

mfiles=[]
bfiles=[]


for file in os.listdir(specify path):
    if file.startswith("drebin"):
        mfiles.append(file)
x=len(mfiles)

for file in os.listdir(specify path):
    if file.startswith("benign"):
        bfiles.append(file)
y=len(bfiles)


# In[5]:


for i in mfiles:
    fname=str(i)
    data=[]
    path1='specify path'+fname
    with open(path1, 'r') as fr:
        data=fr.read()
    path2='specify path'+fname      
    with open(path2, 'w') as fr:
        fr.write(data)

for i in bfiles:
    fname=str(i)
    data=[]
    path1=specify path'+fname
    with open(path1, 'r') as fr:
        data=fr.read()
    path2='specify path'+fname      
    with open(path2, 'w') as fr:
        fr.write(data)

total=x+y
training_m_l=math.ceil(0.7*x)
testing_m_l=x-training_m_l
training_b_l=math.ceil(0.7*y)
testing_b_l=y-training_b_l
training_l=training_m_l+training_b_l
testing_l=testing_m_l+testing_b_l

print("Total Files:", total)
print("Malware Files:",x)
print("Benign Files:",y)
print("----------------------------------------------")
print("Training Files:", training_l)
print("Training Malware Files:", training_m_l)
print("Training Benign Files:", training_b_l)
print("----------------------------------------------")
print("Testing Files:", testing_l)
print("Testing Malware Files:", testing_m_l)
print("Training Benign Files:", testing_b_l)


training_files=[]
testing_files=[]

random.shuffle(mfiles)
random.shuffle(bfiles)


for i in range(len(mfiles)):
    if(i<training_m_l):
        training_files.append(mfiles[i])
    elif(i>=training_m_l):
        testing_files.append(mfiles[i])


for i in range(len(bfiles)):
    if(i<training_b_l):
        training_files.append(bfiles[i])
    elif(i>=training_b_l):
        testing_files.append(bfiles[i])

for i in training_files:
    fname=str(i)
    data=[]
    path1='specify path'+fname
    path2='specify path'+fname
    if 'drebin' in fname:
        path=path1
    elif 'benign' in fname:
        path=path2
    with open(path, 'r') as fr:
        data=fr.read()
    path3='specify path'+fname      
    with open(path3, 'w') as fr:
        fr.write(data)

for i in testing_files:
    fname=str(i)
    data={}
    path1='specify path'+fname
    path2='specify path'+fname
    if 'drebin' in fname:
        path=path1
    elif 'benign' in fname:
        path=path2
    with open(path, 'r') as fr:
        data=fr.read()
    path3='specify path'+fname      
    with open(path3, 'w') as fr:
        fr.write(data)

maxlen=0
files=mfiles+bfiles
random.shuffle(files)
for i in files:
    fname=str(i)
    path1='specify path'+fname
    with open(path1, 'r') as fr:
        data=fr.read()
        temp=len(data.split())
        maxlen=max(maxlen, temp)
        if(temp<500):
            path2='specify path'+"pt1"+fname
            with open(path2, 'w') as fr:
                fr.write(data)
temp=math.ceil(maxlen/500)


overlap=[]
for i in files:
    index=1
    words=0
    store=[]
    overlap=[]
    fname=str(i)
    path1='specify path'+fname
    with open(path1, 'r') as fr:
        lines=fr.readlines()
        y=len(lines)
        for line in lines:
            temp=len(line.split())
            words+=temp
            if(words>=200):
                path2='specify path'+"pt"+str(index)+fname
                with open(path2, 'w') as fr:
                    final=len(store)-3
                    for x in range(len(store)):
                        code=str(store[x])
                        if x>=final:
                            overlap.append(code)
                        fr.write(code)
                words=0
                store=[]
                for j in overlap:
                    words+=len(j.split())
                    store.append(j)
                overlap=[]
                index=index+1
            elif(words<200):
                if(line==lines[y-1]):
                    store.append(line)
                    path2='specify path'+"pt"+str(index)+fname
                    with open(path2, 'w') as fr:
                        for x in store:
                            fr.write(x)
                else:  
                    store.append(line)

split_files=[]
for file in os.listdir('specify path'):
    if file.endswith(".txt"):
        split_files.append(file)

for i in split_files:
    fname=str(i)
    path1='specify path'+fname
    done=[]
    with open(path1, 'r') as fr:
        data=fr.read()
        temp=data.split()
        for i in temp:
            done.append(i)
    with open(path1, 'w') as fr:
        for i in done:
            fr.write(i)
            fr.write(" ")

training_split=[]
testing_split=[]

for i in split_files:
    name=re.sub('pt[0-9]+', '', i)
    if name in training_files:
        training_split.append(i)
    elif name in testing_files:
        testing_split.append(i)


print("Total Split Files:", len(split_files))
print("Total Training Files Split:", len(training_split))
print("Total Testing Files Split:", len(testing_split))


for i in training_split:
    fname=str(i)
    data=[]
    path1='specify path'+fname
    with open(path1, 'r') as fr:
        data=fr.read()
    path2='specify path'+fname      
    with open(path2, 'w') as fr:
        fr.write(data)


for i in testing_split:
    fname=str(i)
    data=[]
    path1='specify path'+fname
    with open(path1, 'r') as fr:
        data=fr.read()
    path2='specify path'+fname      
    with open(path2, 'w') as fr:
        fr.write(data)

final_files=[]
uniq=set()
for i in split_files:
    name=re.sub('pt[0-9]+', '', i)
    uniq.add(name)

for i in uniq:
    s=".*"+i
    r=re.compile(s)
    a=list(filter(r.match, split_files))
    final_files.append(a)
random.shuffle(final_files)


trainingfiles=[]
testingfiles=[]


for file in os.listdir('specify path'):
    if file.endswith(".txt"):
        trainingfiles.append(file)

for file in os.listdir('specify path'):
    if file.endswith(".txt"):
        testingfiles.append(file)

finaltrain=[]
finaltest=[]


uniq=set()
for i in trainingfiles:
    name=re.sub('pt[0-9]+', '', i)
    uniq.add(name)

for i in uniq:
    s=".*"+i
    r=re.compile(s)
    a=list(filter(r.match, trainingfiles))
    finaltrain.append(a)
random.shuffle(finaltrain)

uniq=set()
for i in testingfiles:
    name=re.sub('pt[0-9]+', '', i)
    uniq.add(name)


for i in uniq:
    s=".*"+i
    r=re.compile(s)
    a=list(filter(r.match, testingfiles))
    finaltest.append(a)
random.shuffle(finaltest)


testparts={}
for i in finaltest:
    temp=i
    for x in temp:
        name=re.sub('pt[0-9]+', '', x)
        testparts[name]=len(temp)

parts=[]
uniqfilenames=[]
for k, v in testparts.items():
    parts.append(v)
    uniqfilenames.append(k)

trfiles={}
for i in finaltrain:
    for x in range(len(i)):
        fname=str(i[x])
        path1='specify path'+fname
        with open(path1) as f:
            trfiles[fname]=f.read()


tesfiles={}
for i in finaltest:
    for x in range(len(i)):
        fname=str(i[x])
        path1='specify path'+fname
        with open(path1) as f:
            tesfiles[fname]=f.read()

dftrain=pd.DataFrame(columns=['Fname','Category', 'Code', 'Length'])
for k, v in trfiles.items():
    classes="ok"
    if "drebin" in k:
        classes="Malware"
    else:
        classes="Benign"
    dftrain=dftrain.append({'Fname':k, 'Category': classes, 'Code': v, 'Length':len(v.split())}, ignore_index=True)


dftest=pd.DataFrame(columns=['Fname','Category', 'Code', 'Length'])
for k, v in tesfiles.items():
    classes="ok"
    if "drebin" in k:
        classes="Malware"
    else:
        classes="Benign"
    dftest=dftest.append({'Fname':k, 'Category': classes, 'Code': v, 'Length':len(v.split())}, ignore_index=True)

dfactual=pd.DataFrame(columns=['Fname','ActualCategory'])
for i in uniqfilenames:
    classes="ok"
    if "drebin" in i:
        classes="Malware"
    else:
        classes="Benign"
    dfactual=dfactual.append({'Fname':i, 'ActualCategory':classes }, ignore_index=True)


tempres=[dftrain, dftest]
result=pd.concat(tempres)
result


X=result.Code
tk=Tokenizer() 
tk.fit_on_texts(X)
words=tk.texts_to_sequences(X)
vocab=len(tk.word_index)
print("Maximum number of Unique Words:", vocab)


max_len=-1
for i in range(len(words)):
    if(len(words[i])>max_len):
        max_len=len(words[i])
print("Maximum Length of One File:", max_len)


trwords=[]
tswords=[]
for i in range(len(words)):
    if i<len(trainingfiles):
        temp=words[i]
        trwords.append(temp)
    else:
        temp=words[i]
        tswords.append(temp)


trainx=keras.utils.pad_sequences(trwords, maxlen=max_len)
testx=keras.utils.pad_sequences(tswords, maxlen=max_len)


trainy=dftrain.Category
testy=dftest.Category
le=LabelEncoder()
trainy=le.fit_transform(trainy) 
testy=le.fit_transform(testy) 


early_stopping = EarlyStopping(monitor='val_accuracy', patience=6)

inputs=Input(shape=[max_len]) 
layer=Embedding(vocab+1,64,input_length=max_len)(inputs)#Embedding Layer
layer=LSTM(1024, return_sequences=True)(layer)
layer=LSTM(512)(layer)
layer=Dropout(0.2)(layer)
layer=Dense(1)(layer)
layer=Activation('sigmoid')(layer)
model=Model(inputs=inputs, outputs=layer)


model.compile(loss='binary_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])


print("Training Begins:")
history=model.fit(trainx, trainy, batch_size=16, epochs=13, validation_split=0.2, callbacks=[early_stopping])

print("Predicting on Test Data:")
predictions=model.predict(testx)


predtemp=[]
for i in predictions:
    predtemp.append(i[0])


finalpred=[]
index=0
for i in parts:
    temp=[]
    for y in range(i):
        temp.append(predtemp[index])
        index=index+1
    finalpred.append(temp)
    
testingl=[]
for i in finalpred:
    testingl.append(len(i))

if(parts==testingl):
    print("Keep Moving, no Errors")
else:
    print("ERROR")

classes=[]
for i in finalpred:
    flag=True
    for x in i:
        if(x>=0.5):
            flag=False
            break
        else:
            continue
    if(flag):
        classes.append("Benign")
    else:
        classes.append("Malware")
        
finalf={}
index=0
for k, v in testparts.items():
    finalf[k]=classes[index]
    index=index+1

dfpreds=pd.DataFrame(columns=['Fname','PredictedCategory'])
for k, v in finalf.items():
    dfpreds=dfpreds.append({'Fname':k, 'PredictedCategory': v}, ignore_index=True)
dfpreds

dfactual

print("Evaluating Model:")
score=model.evaluate(testx, testy)

cm=metrics.confusion_matrix(dfactual.ActualCategory, dfpreds.PredictedCategory)

cmap = sns.color_palette("pastel", as_cmap=True)
ax = sns.heatmap((cm/np.sum(cm, axis=1, keepdims=True))*100, annot=True, cmap=cmap, fmt='.2f')
ax.xaxis.tick_top()
ax.set_title('Confusion Matrix\n');
ax.set_xlabel('\nPredicted values')
ax.set_ylabel('Actual Values ');
ax.xaxis.set_ticklabels(['Benign','Malware'])
ax.yaxis.set_ticklabels(['Benign','Malware'])
plt.show()

import pandas as pd
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Calculate metrics
accuracy = accuracy_score(dfactual.ActualCategory, dfpreds.PredictedCategory)
precision =precision_score(dfactual.ActualCategory, dfpreds.PredictedCategory,pos_label='Benign')
recall = recall_score(dfactual.ActualCategory, dfpreds.PredictedCategory,pos_label='Benign')
f1 = f1_score(dfactual.ActualCategory, dfpreds.PredictedCategory, pos_label='Benign')

# Create a table
data = {'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-score'], 
        'Value': [accuracy, precision, recall, f1]}
df = pd.DataFrame(data)
print("Evaluated Parameters: ")
print(df)

